# ğŸ—£ï¸ AI Voice Assistant â€“ GenAI Project

An intelligent voice-enabled assistant built with open-source GenAI technologies. This assistant converts voice to text using OpenAI's Whisper, processes user queries through a locally hosted LLM (TinyLlama) using LangChain, and responds back using Text-to-Speech (TTS). It supports wake-word detection for seamless interaction and utilizes FAISS for persistent memory and contextual conversations.

## ğŸš€ Features

- ğŸ™ï¸ **Voice to Text**: Converts spoken input into text using OpenAI's Whisper.
- ğŸ§  **Natural Language Understanding**: Leverages LangChain + TinyLlama (local LLM) for contextual query understanding and generation.
- ğŸ—£ï¸ **Text to Speech**: Responds using gTTS (Google Text-to-Speech).
- ğŸ’¾ **Memory with FAISS**: Stores and retrieves previous interactions for contextual memory.
- ğŸ”Š **Wake-Word Detection**: Enables always-on assistant functionality.
- ğŸŒ **Streamlit UI**: Clean, interactive web interface to communicate with the assistant.

## ğŸ› ï¸ Tech Stack

- **Python**
- **LangChain**
- **TinyLlama (via Hugging Face Transformers)**
- **Whisper (OpenAI)**
- **gTTS**
- **FAISS**
- **Streamlit**
- **PyTorch**

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourusername/ai-voice-assistant-genai.git
cd ai-voice-assistant-genai
pip install -r requirements.txt
```

Make sure to have `ffmpeg` installed and added to your system path for audio handling.

## ğŸ§ª Run the App

```bash
streamlit run main.py
```

Speak your query after the wake word is detected. The assistant will listen, process, and respond vocally.

## ğŸ§  Architecture

```plaintext
[ğŸ¤ Mic Input] â†’ [ğŸŒ€ Whisper STT] â†’ [ğŸ§  LangChain + TinyLlama] â†’ [ğŸ—‚ FAISS Memory]
                                                        â†“
                                                [ğŸ—£ï¸ gTTS TTS Output]
                                                        â†“
                                               [ğŸ”Š Audio Response]
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ main.py               # Streamlit app launcher
â”œâ”€â”€ voice_input.py        # Handles microphone input and wake-word detection
â”œâ”€â”€ whisper_stt.py        # Whisper integration for speech-to-text
â”œâ”€â”€ llm_response.py       # LangChain + TinyLlama LLM logic
â”œâ”€â”€ tts_output.py         # Text-to-speech response
â”œâ”€â”€ memory_faiss.py       # FAISS-based vector memory store
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ§  Future Enhancements

- Multilingual support
- Emotion-aware responses
- Integration with external APIs for weather, calendar, etc.

## ğŸ¤ Contribution

Feel free to open issues or submit pull requests for enhancements or bug fixes.

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

---

Built with â¤ï¸ using open-source AI.